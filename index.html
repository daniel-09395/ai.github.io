<!DOCTYPE html>
<html>
<head>
  <title>Copy Multiline Variable Text to Clipboard</title>
</head>
<body>
  <button onclick="copyMultilineText1()">p1-Spam Classifier</button>
  <button onclick="copyMultilineText2()">p2-Apriori Algorithm</button>
  <button onclick="copyMultilineText3()">p3-basic crawler</button>
  <button onclick="copyMultilineText4()">p4-Sentiment analysis</button>
  <button onclick="copyMultilineText5()">p5-Link Analysis and PageRank</button>
  <button onclick="copyMultilineText6()">p6-Scrape social media</button>
  <button onclick="copyMultilineText7()">p7-Web Crawling and Indexing</button>
  <button onclick="copyMultilineText8()">p8-focused crawler</button>
  
  <script>
    function copyMultilineText1() {
      // Your variable containing multiline text data
      var yourMultilineVariable = `
      
  import tensorflow as tf
import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

dataset = (
    "Hey, You got a lottery worth of $1000000!",
    "Can we have a lunch today?",
    "Congratulations, you won a prize in RummyCircle!",
    "An amount of $10000 has been credited to your Poker Account",
    "Your meeting will start at 5:00PM Today",
    "it's an important call for you"
)

label = (1,0,1,1,0,0)

max_words, word_len = 1000, 50

tokenizer = Tokenizer(num_words=max_words, oov_token = "<OOV>")
tokenizer.fit_on_texts(dataset)
sequences = tokenizer.texts_to_sequences(dataset)
padded_sequences = pad_sequences(sequences, maxlen=word_len, padding='post', truncating='post')
print(padded_sequences)

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=max_words, output_dim=16),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

training_sequence = np.array(padded_sequences)
training_label = np.array(label)

print("==========================================")
print(training_sequence)

print("==========================================")
print(training_label)

model.fit(training_sequence, training_label, epochs=50)

def check_is_spam(email, threshold = 0.5):
  sequences = tokenizer.texts_to_sequences([email])
  padded_sequences = pad_sequences(sequences, maxlen=word_len, padding='post', truncating='post')
  prediction = model.predict(padded_sequences)[0][0]
  if prediction > threshold:
        print(f"Probably Spam mail, Score: {prediction:.2f}")
  else:
        print(f"Probably Not a Spam mail, Score: {prediction:.2f}")

check_is_spam("hey, congratulations you won a lottery of $200")
check_is_spam("You have meeting today at 3:00 PM")
check_is_spam("Hey, You got a lottery worth of $1000000!")

      
      `;

      // Assign the variable's value to the text variable
      var text = yourMultilineVariable;

      // Create a temporary textarea element to hold the text
      var tempTextArea = document.createElement("textarea");
      tempTextArea.value = text;

      // Append the textarea element to the DOM
      document.body.appendChild(tempTextArea);

      // Select the text in the textarea
      tempTextArea.select();
      tempTextArea.setSelectionRange(0, 99999); /* For mobile devices */

      // Copy the selected text to the clipboard
      document.execCommand("copy");

      // Remove the temporary textarea
      document.body.removeChild(tempTextArea);

      
    }
    function copyMultilineText2() {
      // Your variable containing multiline text data
      var yourMultilineVariable = `
      
  from mlxtend.frequent_patterns import apriori
from mlxtend.frequent_patterns import association_rules

import pandas as pd


dataset = [
    ['Milk', 'Bread','Nuts'],
     ['Milk', 'Bread'],
      ['Milk', 'Eggs','Nuts'],
       ['Milk', 'Bread','Eggs'],
        ['Bread', 'Nuts'],
    ]

df = pd.DataFrame(dataset)
print("")
print("------:Database:------")
print(df)

df_encoded = pd.get_dummies(df, prefix='',prefix_sep='')
print("------:Encoded:------")
print(df_encoded)

frequent_itemsets = apriori(df_encoded, min_support=0.5, use_colnames=True)
print("------:Frequent Itemsets:------")
print(frequent_itemsets)

rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.1)
print("------:Association Rules:------")
print(rules)
print("")

     
      `;

      // Assign the variable's value to the text variable
      var text = yourMultilineVariable;

      // Create a temporary textarea element to hold the text
      var tempTextArea = document.createElement("textarea");
      tempTextArea.value = text;

      // Append the textarea element to the DOM
      document.body.appendChild(tempTextArea);

      // Select the text in the textarea
      tempTextArea.select();
      tempTextArea.setSelectionRange(0, 99999); /* For mobile devices */

      // Copy the selected text to the clipboard
      document.execCommand("copy");

      // Remove the temporary textarea
      document.body.removeChild(tempTextArea);

      
    }
     function copyMultilineText3() {
      // Your variable containing multiline text data
      var yourMultilineVariable = `

print(" ")
import requests
from bs4 import BeautifulSoup
import re

def crawl_and_search(url, keyword):
  try:
    # Fetch the content from the URL
    response = requests.get(url)
    response.raise_for_status() # Check if the request was successful
    page_content = response.text

    # Parse the content using BeautifulSoup
    soup = BeautifulSoup(page_content, 'html.parser')

    # Extract the text from the page
    text = soup.get_text()

    # Search for the keyword in the text
    if re.search(keyword, text, re. IGNORECASE):
      print(f"Keyword '{keyword}' found in {url}")
    else:
      print(f"Keyword '{keyword}' not found in {url}")

  except requests.exceptions. RequestException as e:
    print(f"Failed to retrieve {ur1}: {e}")

# Define the URL and the keyword to search for
url = input("Enter the URL to crawl: ")
keyword = input("Enter the keyword to search for: ")

# Start the crawling process
crawl_and_search(url, keyword)
print(" ")

      
      `;

      // Assign the variable's value to the text variable
      var text = yourMultilineVariable;

      // Create a temporary textarea element to hold the text
      var tempTextArea = document.createElement("textarea");
      tempTextArea.value = text;

      // Append the textarea element to the DOM
      document.body.appendChild(tempTextArea);

      // Select the text in the textarea
      tempTextArea.select();
      tempTextArea.setSelectionRange(0, 99999); /* For mobile devices */

      // Copy the selected text to the clipboard
      document.execCommand("copy");

      // Remove the temporary textarea
      document.body.removeChild(tempTextArea);

      
    }
    function copyMultilineText4() {
      // Your variable containing multiline text data
      var yourMultilineVariable = `

print(" ")
import nltk
from nltk. sentiment.vader import SentimentIntensityAnalyzer
import matplotlib.pyplot as plt
import seaborn as sns

print("")
# Step 1: Download VADER lexicon if not already done
nltk.download('vader_lexicon')

# Step 2: Initialize the VADER sentiment intensity analyzer
sia = SentimentIntensityAnalyzer()

# Step 3: List of customer reviews
reviews = [
    "The product quality is amazing, I'm very satisfied!",
    "Terrible service, I will never buy from here again.",
    "Decent product, but shipping was too slow.",
    "Absolutely love it! Will recommend to everyone.",
    "Not worth the money, very disappointing.",
    "Great experience overall, but could improve the packaging.",
    "Mediocre, not what I expected.",
    "Excellent value for the price, highly recommended.",
    "Worst purchase I've made this year.",
    "It's okay, nothing special."
    ]

# Step 4: Analyze sentiment for each review
sentiments = []
for review in reviews:
  sentiment_score = sia.polarity_scores(review)
  compound_score = sentiment_score['compound' ]

  if compound_score >= 0.05:
    sentiments. append('Positive')
  elif compound_score <= -0.05:
    sentiments.append('Negative' )
  else:
    sentiments.append('Neutral')

# Step 5: Count the occurrences of each sentiment
sentiment_counts = {
'Positive': sentiments. count('Positive'),
'Negative': sentiments.count('Negative'),
'Neutral': sentiments. count('Neutral')
}

# Step 6: Visualization
sns.set(style="whitegrid")
plt.figure(figsize=(8, 6))
sns.barplot(x=list(sentiment_counts.keys()), y=list(sentiment_counts.values()),
palette="viridis")
plt.title('Sentiment Analysis of Customer Reviews')
plt.xlabel('Sentiment' )
plt.ylabel ('Number of Reviews')
plt.show()
print(" ")
      
      `;

      // Assign the variable's value to the text variable
      var text = yourMultilineVariable;

      // Create a temporary textarea element to hold the text
      var tempTextArea = document.createElement("textarea");
      tempTextArea.value = text;

      // Append the textarea element to the DOM
      document.body.appendChild(tempTextArea);

      // Select the text in the textarea
      tempTextArea.select();
      tempTextArea.setSelectionRange(0, 99999); /* For mobile devices */

      // Copy the selected text to the clipboard
      document.execCommand("copy");

      // Remove the temporary textarea
      document.body.removeChild(tempTextArea);

      
    }
    function copyMultilineText5() {
      // Your variable containing multiline text data
      var yourMultilineVariable = `

print(" ")
import networkx as nx
G = nx.random_k_out_graph(n=8, k=2, alpha=0.5)

def draw_graph(G):
  nx.draw_circular(G, node_size=400, with_labels=True)

draw_graph(G)

ranks_pr = nx.pagerank(G)
print("PageRank:")

print(ranks_pr)
print(" ")

`;

      // Assign the variable's value to the text variable
      var text = yourMultilineVariable;

      // Create a temporary textarea element to hold the text
      var tempTextArea = document.createElement("textarea");
      tempTextArea.value = text;

      // Append the textarea element to the DOM
      document.body.appendChild(tempTextArea);

      // Select the text in the textarea
      tempTextArea.select();
      tempTextArea.setSelectionRange(0, 99999); /* For mobile devices */

      // Copy the selected text to the clipboard
      document.execCommand("copy");

      // Remove the temporary textarea
      document.body.removeChild(tempTextArea);

      
    }
    function copyMultilineText6() {
      // Your variable containing multiline text data
      var yourMultilineVariable = `

print(" ")
import requests
from bs4 import BeautifulSoup


def check_word_in_webpage(url, word):
  response = requests. get(url)

  if response.status_code == 200:
    soup = BeautifulSoup(response.content,'html.parser')
    text_content = soup.get_text()

    if word.lower() in text_content.lower():
      print(f"The word '{word}' is present in the webpage.")
    else:
      print(f"The word '{word}' is not present in the webpage.")
  else:
    print("Failed to retrieve webpage.")

url = input("Enter the url you want to Scrap : ")
word_to_check = input("Enter the text you want to know which is present or not : ")
check_word_in_webpage(url, word_to_check)
print(" ")


`;

      // Assign the variable's value to the text variable
      var text = yourMultilineVariable;

      // Create a temporary textarea element to hold the text
      var tempTextArea = document.createElement("textarea");
      tempTextArea.value = text;

      // Append the textarea element to the DOM
      document.body.appendChild(tempTextArea);

      // Select the text in the textarea
      tempTextArea.select();
      tempTextArea.setSelectionRange(0, 99999); /* For mobile devices */

      // Copy the selected text to the clipboard
      document.execCommand("copy");

      // Remove the temporary textarea
      document.body.removeChild(tempTextArea);

      
    }
    function copyMultilineText7() {
      // Your variable containing multiline text data
      var yourMultilineVariable = ` 
      
print(" ")
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import re
import nltk

# Seed URLs
seed_urls = ['https://indianexpress.com/section/india/', 'https://www.indianretailer.com/restaurant/']
# Keywords to focus on
nltk.download('stopwords')
nltk.download('punkt_tab')

keywords = ['restaurant', 'food', 'local']

# Stop words (to filter out common words)
stop_words = set(stopwords.words('english'))
# Visited URLs
visited = set()

def is_relevant(content, keywords):
#Check if the content is relevant based on the keywords.
  words = word_tokenize(content.lower())
  words = [w for w in words if w.isalnum() and w not in stop_words]
  return any(keyword in words for keyword in keywords)

def crawl(url):
#Crawl a single webpage.
  try:
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    text = soup.get_text()

# Check if the content is relevant
    if is_relevant(text, keywords):
      print(f"Relevant content found at: {url}")
# Here you could save the content to a file or database

# Extract links and follow them
      for link in soup.find_all('a', href=True):
        new_url = urljoin(url, link['href'])
        if new_url not in visited and re.match(r'^https ?: //', new_url):
          visited.add(new_url)
          crawl(new_url)
  except requests.exceptions.RequestException as e:
    print(f"Error crawling {url}: {e}")

# Start crawling from the seed URLs
for url in seed_urls:
  if url not in visited:
    visited.add(url)
    print(crawl(url))
print(" ")

      `;

      // Assign the variable's value to the text variable
      var text = yourMultilineVariable;

      // Create a temporary textarea element to hold the text
      var tempTextArea = document.createElement("textarea");
      tempTextArea.value = text;

      // Append the textarea element to the DOM
      document.body.appendChild(tempTextArea);

      // Select the text in the textarea
      tempTextArea.select();
      tempTextArea.setSelectionRange(0, 99999); /* For mobile devices */

      // Copy the selected text to the clipboard
      document.execCommand("copy");

      // Remove the temporary textarea
      document.body.removeChild(tempTextArea);

      
    }
     function copyMultilineText8() {
      // Your variable containing multiline text data
      var yourMultilineVariable = `

print(" ")
!pip install praw
import praw
import pandas as pd

# Ensure that your actual client_id, client_secret, and user_agent are entered here without any leading/trailing spaces or invalid characters
reddit = praw.Reddit(client_id=' ', client_secret=' ', user_agent=' ')

sub_name = input("enter the Keyword")
max_posts = 5

# Enable read-only mode
reddit.read_only = True
title=[]
for submission in reddit.subreddit(sub_name).new(limit=max_posts):
  title.append(submission.title)
print(title)
print(" ")

`;

      // Assign the variable's value to the text variable
      var text = yourMultilineVariable;

      // Create a temporary textarea element to hold the text
      var tempTextArea = document.createElement("textarea");
      tempTextArea.value = text;

      // Append the textarea element to the DOM
      document.body.appendChild(tempTextArea);

      // Select the text in the textarea
      tempTextArea.select();
      tempTextArea.setSelectionRange(0, 99999); /* For mobile devices */

      // Copy the selected text to the clipboard
      document.execCommand("copy");

      // Remove the temporary textarea
      document.body.removeChild(tempTextArea);

      
    }
  </script>
</body>
</html>
